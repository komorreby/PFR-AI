# PFR-AI: Cистема аналитики для ПФР

«Разработка интеллектуальной системы автоматизированного анализа и верификации пенсионных документов с использованием методов машинного 
обучения и обработки текстов»

Прототип веб-приложения для ввода данных пенсионных дел, их анализа на предмет ошибок, **анализа соответствия законодательству с помощью RAG** и отображения истории обработанных дел.

## Основные возможности

*   **Ввод данных:** Многошаговая форма для ввода персональных данных, информации о трудовом стаже и других сведений.
*   **Анализ дела:** Отправка введенных данных на бэкенд для:
    *   Проверки на основе предобученной модели классификации ошибок.
    *   **Анализа соответствия ФЗ-400 "О страховых пенсиях" с использованием Retrieval-Augmented Generation (RAG), графа знаний для обогащения контекста и локального LLM.**
*   **Отображение истории:** Вывод списка обработанных дел с их статусом и результатами анализа.
*   **Отображение ошибок:** Вывод списка обнаруженных ошибок и рекомендаций после анализа.
*   **RAG Анализ:** Возможность запросить анализ введенных данных на соответствие законодательству и получить текстовый ответ от RAG-системы.
*   **Экспорт документов:** Загрузка результатов анализа в форматах PDF и DOCX.

## Конфигурация типов пенсий и требуемых документов

Система использует конфигурационные JSON-файлы для определения типов пенсий и требуемых документов:

### Структура конфигурации

* **`backend/config_data/pension_types.json`** - содержит информацию о доступных типах пенсий:
  * `id` - уникальный идентификатор типа пенсии
  * `display_name` - отображаемое название типа пенсии
  * `description` - описание типа пенсии

* **`backend/config_data/document_requirements.json`** - определяет требования к документам для каждого типа пенсии:
  * Ключи соответствуют `id` типов пенсий
  * Для каждого типа пенсии определен список документов:
    * `id` - уникальный идентификатор документа
    * `name` - название документа
    * `description` - описание документа
    * `is_critical` - является ли документ обязательным
    * `ocr_type` - тип документа для OCR-системы (если применимо)
    * `condition_text` - текстовое описание условия, при котором требуется документ

### API для работы с конфигурацией

* **`GET /api/v1/pension_types`** - получение списка всех доступных типов пенсий
* **`GET /api/v1/pension_documents/{pension_type_id}`** - получение списка требуемых документов для указанного типа пенсии

### Преимущества подхода

* Централизованное управление типами пенсий и требованиями к документам
* Возможность легко добавлять новые типы пенсий и документы без изменения кода
* Единый источник информации для фронтенда и бэкенда
* Автоматическая валидация данных с использованием Pydantic-моделей

## API для обработки пенсионных дел

Система предлагает современный асинхронный API для работы с пенсионными делами:

### Работа с пенсионными делами:

* **`POST /api/v1/cases`** - создание нового дела с асинхронной обработкой
  * Принимает JSON-объект типа `CaseDataInput` с данными пенсионного дела
  * Немедленно возвращает ID созданного дела со статусом `PROCESSING`
  * Выполняет RAG-анализ в фоновом режиме
  * Статус код: `202 Accepted`

* **`GET /api/v1/cases/{case_id}`** - получение полной информации о деле.
  * Возвращает объект `FullCaseData`.

* **`GET /api/v1/cases/{case_id}/status`** - получение статуса и результатов обработки дела
  * Возвращает текущий статус обработки, объяснение и оценку уверенности (`ProcessOutput`).

* **`GET /api/v1/cases/history`** - получение истории дел.
  * Поддерживает пагинацию (`skip`, `limit`).
  * Возвращает список `CaseHistoryEntry`.

* **`GET /api/v1/cases/{case_id}/document`** - скачивание сгенерированного документа по делу.
  * Параметры: `format` (`pdf` или `docx`).

### Асинхронная обработка документов:

* **`POST /api/v1/document_extractions`** - отправка документа на асинхронное распознавание
  * Принимает изображение документа через `multipart/form-data`
  * Поддерживает типы документов: паспорт, СНИЛС, трудовая книжка и другие
  * Немедленно возвращает `task_id` для отслеживания задачи
  * Выполняет OCR и извлечение данных в фоновом режиме
  * Статус код: `202 Accepted`

* **`GET /api/v1/document_extractions/{task_id}`** - получение результатов распознавания документа
  * Возвращает статус задачи (`PROCESSING`, `COMPLETED`, `FAILED`)
  * При успешном завершении возвращает структурированные данные из документа

### Структура ответа при ошибках

Для стандартизации ответов об ошибках используется следующая структура:

```json
{
  "error_code": "UNIQUE_ERROR_CODE", // Опциональный уникальный код ошибки
  "message": "Человекочитаемое сообщение об ошибке",
  "details": { /* Дополнительные детали, например, ошибки валидации по полям */ }
}
```

В частности, при ошибках валидации входных данных (статус 422), поле `details` будет содержать массив объектов с информацией о каждом невалидном поле:

```json
{
  "error_code": "VALIDATION_ERROR",
  "message": "Ошибка валидации входных данных.",
  "details": [
    {
      "field": "имя.поля.в.запросе",
      "message": "сообщение об ошибке валидации для этого поля",
      "type": "тип ошибки валидации"
    }
    // ... другие поля с ошибками
  ]
}
```

### Преимущества асинхронной обработки

* **Отзывчивость API:** Клиент не ждет завершения длительных операций
* **Масштабируемость:** Возможность обработки множества запросов параллельно
* **Устойчивость к сбоям:** Ошибки в фоновых задачах не прерывают работу основного приложения
* **Мониторинг:** Подробное логирование всех этапов обработки

## Распознавание данных с изображений документов

Система способна извлекать структурированные данные из фотографий следующих типов документов:
*   Паспорт РФ
*   СНИЛС
*   Другие пенсионные документы (справки, выписки, удостоверения и т.д.)

### Процесс распознавания:

1.  **Загрузка изображения:** Пользователь загружает изображение документа через API.
2.  **Анализ мультимодальной LLM (`qwen2.5vl`):**
    *   Для **паспортов** и **СНИЛС** модель извлекает ключевые поля согласно predefined Pydantic моделям.
    *   Для **"других" документов** модель определяет тип документа, извлекает все найденные поля, предоставляет свою оценку уверенности и полный распознанный текст.
3.  **Дополнительный анализ текстовой LLM (`qwen3`) (для "других" документов):**
    *   Результаты от `qwen2.5vl` (тип документа, извлеченные поля, оценка, полный текст) передаются модели `qwen3`.
    *   `qwen3` предоставляет развернутое осмысление документа и, что важно, **стандартизирует определенный `qwen2.5vl` тип документа** согласно предопределенному списку (`PENSION_DOCUMENT_TYPES`). Это позволяет привести разнообразные формулировки типов документов к единому стандарту.
4.  **Возврат результата:** API возвращает извлеченные и структурированные данные в формате JSON.

### Ключевые технологии и подходы:

*   **Ollama:** Используется для локального запуска мультимодальной (`qwen2.5vl:latest`) и текстовой (`qwen3:latest`) LLM.
*   **Pydantic модели:** Для валидации и структурирования извлекаемых данных (`PassportData`, `SnilsData`, `OtherDocumentData`).
*   **Промпт-инжиниринг:** Тщательно разработанные промпты для каждой модели и типа документа для повышения точности извлечения.
*   **Двухэтапный анализ для "других" документов:** Комбинация мультимодальной LLM для первичного извлечения и текстовой LLM для глубокого анализа и стандартизации.
*   **Обработка ошибок и парсинг:** Надежные механизмы для извлечения JSON из ответов LLM, включая очистку от Markdown-разметки.

## Технологический стек

### Фронтенд

*   Next.js, React
*   Daisy UI, Tailwind CSS
*   Zustand
*   TypeScript

### Бэкенд

*   FastAPI (Python 3.10+)
*   PyTorch, scikit-learn
*   LlamaIndex
*   Neo4j (граф знаний пенсионного законодательства)
*   Языковые модели:
    *   Mistral 7B (для анализа соответствия законодательству)
    *   Bert-подобная модель (для классификации ошибок в пенсионном деле)

## Архитектура системы

### Retrieval-Augmented Generation (RAG)

Система использует гибридный подход RAG для ответов на вопросы о пенсионном законодательстве:

1. **Индексация документов:** Загрузка и индексация законов о пенсионном обеспечении в векторную базу данных.
2. **Гибридный поиск:** При получении запроса система использует комбинацию трех методов поиска для нахождения релевантного контекста:
   * **Векторный поиск:** Семантический поиск с использованием эмбеддингов для нахождения контекстно-близких фрагментов.
   * **BM25 поиск:** Статистический поиск на основе частотности ключевых слов для улучшения точности по ключевым терминам запроса.
   * **Графовый поиск:** Использование графа знаний для нахождения статей, релевантных типам пенсий, упомянутым в запросе.
3. **Объединение результатов и дедупликация:** Результаты из трёх методов поиска объединяются и дедуплицируются для получения наиболее полного и точного набора контекстных данных.
4. **Реранжирование:** Полученные фрагменты ранжируются с использованием специализированной модели для выявления наиболее релевантных данных.
5. **Генерация ответа:** На основе выбранных фрагментов и запроса пользователя LLM генерирует структурированный ответ с юридическим обоснованием.

### Граф знаний пенсионного законодательства

Система использует Neo4j для хранения структурированной информации о пенсионном законодательстве:

* **Узлы графа:**
  * Law - законы (ФЗ-400, ФЗ-166 и др.)
  * Article - статьи законов
  * PensionType - типы пенсий (страховая по старости, социальная по инвалидности и др.)

* **Связи:**
  * CONTAINS - закон содержит статью
  * RELATES_TO_PENSION_TYPE - статья относится к определённому типу пенсии

### Масштабируемость и производительность

Система обеспечивает высокую производительность и масштабируемость за счет:

* **Асинхронная обработка:** Все длительные операции (RAG-анализ, OCR, генерация документов) выполняются асинхронно
* **Фоновые задачи:** Использование BackgroundTasks для обработки запросов без блокировки основного потока
* **Персистентное хранение задач:** Перенос данных о задачах из временного хранилища в БД для надежности и масштабируемости
* **Механизм TTL:** Автоматическая очистка устаревших задач и данных для управления жизненным циклом задач
* **Мониторинг задач:** API для получения статистики по задачам (статусы, типы документов, время обработки)
* **Многоуровневое кэширование:**
  * Кэширование результатов OCR для быстрого доступа к часто запрашиваемым документам
  * Кэширование результатов RAG-анализа для схожих запросов
  * Автоматическое очищение кэша на основе TTL

### Инструменты для диагностики и обогащения графа знаний

В проекте реализованы специальные инструменты для анализа и улучшения графа знаний:

* **`graph_validator.py`** - модуль для диагностики состояния графа и выполнения базовых исправлений:
  * Поиск изолированных статей (без связей с типами пенсий)
  * Выявление и исправление дублирующихся узлов
  * Создание базовых связей между статьями и типами пенсий

* **`graph_enricher.py`** - инструмент для обогащения графа знаний:
  * Интеграция с RAG-движком для анализа текстов статей
  * Улучшенный поиск ключевых слов для создания связей
  * Формирование подробных отчетов о состоянии графа

Использование этих инструментов позволяет существенно повысить качество и полноту графа знаний, что напрямую влияет на качество ответов системы.

#### Запуск инструментов для работы с графом

```bash
# Проверка состояния графа знаний
python -m app.graph_enricher --action status

# Применение базовых исправлений
python -m app.graph_enricher --action basic

# Исправление дублирующихся узлов
python -m app.graph_enricher --action duplicates

# Обогащение графа данными из векторного хранилища
python -m app.graph_enricher --action vector --max-nodes 500

# Полное обогащение графа (включая все вышеперечисленные действия)
python -m app.graph_enricher --action full --report graph_report.json
```

## Запуск проекта

### Требования

*   Python 3.10+
*   Node.js 20+
*   Neo4j 4.4+

### Бэкенд

```bash
cd backend
python -m pip install -r requirements.txt
uvicorn app.main:app --reload
```

### Фронтенд

```bash
cd frontend
npm install
npm run dev
```

### Инициализация Neo4j

```bash
# Запуск Neo4j в Docker
docker run \
    --publish=7474:7474 --publish=7687:7687 \
    --env=NEO4J_AUTH=neo4j/12345678 \
    neo4j:latest
```

## Структура проекта

```
PFR-AI/
├── backend/
│   ├── app/
│   │   ├── rag_core/           # Модули системы RAG
│   │   │   ├── config.py       # Конфигурация RAG и графа знаний
│   │   │   ├── engine.py       # Основной движок RAG
│   │   │   └── document_parser.py # Парсер документов с извлечением данных для графа
│   │   ├── models/
│   │   │   └── config_models.py # Pydantic модели для конфигурации
│   │   ├── config_loader.py    # Загрузчик JSON-конфигураций
│   │   ├── graph_builder.py    # Построение графа знаний в Neo4j
│   │   ├── graph_validator.py  # Диагностика и валидация графа знаний
│   │   ├── graph_enricher.py   # Обогащение графа знаний
│   │   ├── crud.py             # Операции с базой данных (CRUD)
│   │   ├── database.py         # Настройка SQLAlchemy и соединения
│   │   ├── main.py             # Основной файл FastAPI (точка входа, эндпоинты)
│   │   ├── models.py           # Pydantic модели
│   │   └── services.py         # Сервисный слой (генерация документов и т.п.)
│   ├── config_data/
│   │   ├── pension_types.json  # Конфигурация типов пенсий
│   │   └── document_requirements.json # Требования к документам
│   └── requirements.txt
├── frontend/
│   ├── app/
│   ├── components/
│   └── package.json
├── docs/
│   ├── graph_ontology.md       # Описание онтологии графа знаний
│   └── ...
└── README.md
```

## Быстрый старт

### Предпосылки

*   Установлен Python 3.9+
*   Установлен Node.js и npm/yarn
*   **Установлен и запущен Ollama** с необходимыми моделями (например, `gemma3`, `mxbai-embed-large`). Убедитесь, что Ollama доступен по адресу `http://localhost:11434`.
*   **Установлен и запущен Neo4j** для работы с графом знаний. Убедитесь, что Neo4j доступен по адресу `bolt://localhost:7687` с указанными в `backend/app/rag_core/config.py` учетными данными.

### Бэкенд

1.  Перейдите в директорию `backend`:
    ```bash
    cd backend
    ```
2.  Создайте и активируйте виртуальное окружение:
    ```bash
    python -m venv venv
    # Windows
    .\venv\Scripts\activate
    # macOS/Linux
    source ./venv/bin/activate
    ```
3.  Установите зависимости:
    ```bash
    pip install -r requirements.txt
    ```
4.  **(Первый запуск) Инициализация RAG индекса и графа знаний:** При первом запуске сервера FastAPI произойдет автоматическая индексация документа из папки `backend/data` и построение графа знаний в Neo4j. Это может занять несколько минут. Следите за логами в консоли.
5.  Запустите сервер FastAPI:
    ```bash
    uvicorn app.main:app --reload --port 8000
    ```
    Сервер будет доступен по адресу `http://127.0.0.1:8000`.

### Фронтенд

1.  Перейдите в директорию `frontend`:
    ```bash
    cd frontend
    ```
2.  Установите зависимости:
    ```bash
    npm install
    ```
3.  Запустите сервер для разработки:
    ```bash
    npm run dev
    ```
    Приложение будет доступно по адресу `http://localhost:5173` (или другому порту, указанному Vite).

## Дальнейшие шаги

*   См. `backend/README.md` для детальной информации о бэкенде.
*   См. `frontend/README.md` для детальной информации о фронтенде.

## API Эндпоинты

### Аутентификация

*   `POST /api/v1/auth/token` - Получение JWT токена.
    *   Тело запроса: `application/x-www-form-urlencoded` с полями `username` и `password`.
    *   Возвращает: `access_token` и `token_type`.
*   `GET /api/v1/users/me` - Получение информации о текущем пользователе.
    *   Требует: Заголовок `Authorization: Bearer <token>`.
    *   Возвращает: Информацию о пользователе (id, username, role, is_active).

### Работа с делами (Cases)

*   `POST /api/v1/cases` - Создание нового дела и запуск его обработки.
    *   Требует: Роль 'manager' или 'admin'.
    *   Тело запроса: `CaseDataInput` (JSON).
    *   Возвращает: `ProcessOutput` со статусом `PROCESSING` и `case_id`. Обработка происходит в фоновом режиме.
*   `GET /api/v1/cases/{case_id}/status` - Получение статуса и результатов обработки дела.
    *   Требует: Роль 'manager' или 'admin'.
    *   Возвращает: `ProcessOutput` с текущим статусом, объяснением и оценкой уверенности.
*   `GET /api/v1/cases/{case_id}` - Получение полной информации о деле.
    *   Требует: Роль 'manager' или 'admin'.
    *   Возвращает: `FullCaseData` со всеми данными дела.
*   `GET /api/v1/cases/history` - Получение истории дел.
    *   Требует: Роль 'manager' или 'admin'.
    *   Параметры запроса: `skip` (int, опционально), `limit` (int, опционально).
    *   Возвращает: Список `CaseHistoryEntry`.
*   `GET /api/v1/cases/{case_id}/document` - Скачивание сгенерированного документа по делу.
    *   Требует: Роль 'manager' или 'admin'.
    *   Параметры запроса: `format` ("pdf" или "docx").
    *   Возвращает: Файл документа.

### Конфигурация и справочная информация

*   `GET /api/v1/pension_types` - Получение списка доступных типов пенсий.
    *   Требует: Любой аутентифицированный пользователь.
    *   Возвращает: Список словарей с `id`, `display_name`, `description`.
*   `GET /api/v1/pension_documents/{pension_type_id}` - Получение списка требуемых документов для указанного типа пенсии.
    *   Требует: Любой аутентифицированный пользователь.
    *   Возвращает: Список `DocumentDetail`.
*   `GET /api/v1/standard_document_names` - Получение списка стандартных имен документов (для OCR).
    *   Требует: Любой аутентифицированный пользователь.
    *   Возвращает: Список строк.

### OCR (Извлечение данных из документов)

*   `POST /api/v1/document_extractions` - Загрузка изображения документа для извлечения данных.
    *   Требует: Роль 'manager' или 'admin'.
    *   Тело запроса: `multipart/form-data` с полями `document_type` (тип из `DocumentTypeToExtract`) и `image` (файл).
    *   Параметр запроса: `ttl_hours` (int, опционально, время жизни задачи в часах).
    *   Возвращает: `OcrTaskSubmitResponse` со статусом `PROCESSING` и `task_id`. Обработка происходит в фоновом режиме.
*   `GET /api/v1/document_extractions/{task_id}` - Получение статуса и результатов задачи извлечения данных.
    *   Требует: Роль 'manager' или 'admin'.
    *   Возвращает: `OcrTaskStatusResponse` с текущим статусом и результатами (если готовы).
*   `GET /api/v1/tasks/stats` - Получение статистики по задачам OCR.
    *   Требует: Роль 'manager' или 'admin'.
    *   Возвращает: `TasksStatsResponse` со статистикой.

### Управление документами RAG

*   `POST /api/v1/documents` - Загрузка нового документа для RAG.
    *   Требует: Роль 'admin'.
    *   Тело запроса: `multipart/form-data` с полем `file` (файл документа).
    *   Возвращает: `DocumentUploadResponse` с именем файла и сообщением. Переиндексация запускается в фоновом режиме.
    *   Поддерживаемые типы файлов: PDF.
*   `GET /api/v1/documents` - Получение списка загруженных документов RAG.
    *   Требует: Роль 'manager' или 'admin'.
    *   Возвращает: `DocumentListResponse` со списком имен PDF-файлов.
*   `DELETE /api/v1/documents/{filename}` - Удаление документа RAG.
    *   Требует: Роль 'admin'.
    *   Возвращает: `DocumentDeleteResponse` с именем удаленного файла и сообщением. Переиндексация запускается в фоновом режиме.

### Сервис

*   `GET /api/v1/health` - Проверка состояния сервиса и его зависимостей.
    *   Возвращает: `HealthCheckResponse` с информацией о статусе БД, Ollama LLM, Ollama Vision, Neo4j.

## Запуск

1.  **Установка зависимостей:**
    ```bash
    pip install -r requirements.txt
    ```
2.  **Создание файла `.env`:**
    Скопируйте `.env.example` в `.env` и заполните необходимые переменные окружения:
    *   `SECRET_KEY`: Секретный ключ для JWT.
    *   `ACCESS_TOKEN_EXPIRE_MINUTES`: Время жизни токена доступа.
    *   `OLLAMA_BASE_URL`: URL вашего экземпляра Ollama.
    *   `NEO4J_URI`, `NEO4J_USER`, `NEO4J_PASSWORD`, `NEO4J_DATABASE`: Данные для подключения к Neo4j.
    *   Другие переменные, если необходимо (например, для моделей).
3.  **Создание первоначальных пользователей (опционально):**
    Выполните скрипт `create_initial_users.py` для создания пользователей 'admin' и 'manager' (пароли будут выведены в консоль):
    ```bash
    python create_initial_users.py
    ```
    Пароли по умолчанию: `admin_password` для `admin` и `manager_password` для `manager`. **Обязательно смените их в реальном окружении!**
4.  **Запуск FastAPI приложения:**
    ```bash
    uvicorn backend.app.main:app --reload --host 0.0.0.0 --port 8000
    ```
    Приложение будет доступно по адресу `http://localhost:8000`. Документация API (Swagger UI) будет доступна по `http://localhost:8000/docs`.

## Структура директорий RAG Core

*   `backend/app/rag_core/data/docs/`: Директория для хранения исходных документов (PDF), которые будут индексироваться.
*   `backend/app/rag_core/data/index/`: Директория для хранения персистентного индекса LlamaIndex.
*   `backend/app/rag_core/data/logs/`: Логи, связанные с индексацией и RAG.

## Переменные окружения

Основные переменные окружения настраиваются в файле `.env`. Смотрите `.env.example` для полного списка.

### Для RAG:

*   `DOCUMENTS_DIR`: Путь к директории с документами для индексации.
*   `PERSIST_DIR`: Путь к директории для сохранения индекса.
*   `PARAMS_LOG_FILE`: Путь к файлу для логгирования параметров индекса.
*   `OLLAMA_BASE_URL`: Базовый URL для Ollama.
*   `OLLAMA_LLM_MODEL_NAME`: Имя основной LLM модели в Ollama.
*   `HF_EMBED_MODEL_NAME`: Имя модели эмбеддингов на Hugging Face (например, `jinaai/jina-embeddings-v3-base-ru`).
*   `RERANKER_MODEL_NAME`: Имя модели реранжировщика на Hugging Face (например, `BAAI/bge-reranker-base`).
*   `NEO4J_URI`, `NEO4J_USER`, `NEO4J_PASSWORD`, `NEO4J_DATABASE`: Параметры подключения к Neo4j.

## Использование графа знаний (Neo4j)

RAG система использует граф знаний Neo4j для улучшения извлечения информации и построения связей между документами, статьями законов и типами пенсий.

*   **Построение графа:** При первоначальной индексации документов (`_parse_documents_async` в `engine.py`) извлекаются сущности и отношения, которые затем загружаются в Neo4j с помощью `KnowledgeGraphBuilder`.
*   **Обогащение запросов:** `GraphRetriever` используется для извлечения релевантных узлов (статей) из графа на основе типов пенсий, упомянутых в запросе.
*   **Обогащение узлов:** Перед передачей в LLM, извлеченные узлы могут быть дополнительно обогащены информацией из графа (например, связанные условия, другие типы пенсий).
*   **Инструменты для графа:**
    *   `backend/app/graph_validator.py`: Содержит `PensionGraphValidator` для проверки и исправления структуры графа.
    *   `backend/app/graph_enricher.py`: Содержит `GraphEnricher` для запуска полного цикла валидации, исправления и обогащения графа.
    *   `backend/app/demo_graph_tools.py`: Демонстрационный скрипт для запуска инструментов `GraphEnricher`.

## Запуск инструментов для графа

Для запуска демонстрации инструментов работы с графом (диагностика, исправление, обогащение):
```bash
python backend/app/demo_graph_tools.py
```
Скрипт предложит подтвердить запуск и выполнит несколько этапов, выводя информацию в консоль и сохраняя лог и отчет.

Либо можно использовать `GraphEnricher` из командной строки:
```bash
python backend/app/graph_enricher.py --action [status|basic|vector|duplicates|full] [--report path/to/report.json]
```
Примеры:
*   Получить текущий статус графа: `python backend/app/graph_enricher.py --action status`
*   Выполнить полное обогащение и сохранить отчет: `python backend/app/graph_enricher.py --action full --report graph_report.json`

## TODO / Возможные улучшения

*   **Асинхронность:** Полный переход на асинхронные операции для всех I/O bound задач (Neo4j, файловая система).
*   **Конфигурация:** Более гибкая конфигурация моделей и параметров RAG через файлы или переменные окружения.
*   **Безопасность:** Улучшение безопасности, включая более строгие проверки прав доступа, валидацию вводимых данных.
*   **Тестирование:** Расширение покрытия тестами.
*   **Версионирование API:** Внедрение версионирования для API эндпоинтов.
*   **Обработка ошибок:** Более детальная и стандартизированная обработка ошибок.
*   **Мониторинг и логирование:** Интеграция с системами мониторинга и логирования.
*   **Frontend:** Улучшение интерфейса, добавление возможности управления пользователями, документами RAG и просмотра логов.
*   **Управление моделями:** Возможность выбора и переключения моделей LLM/Embeddings/Reranker "на лету" через API или UI.
*   **Кеширование:** Более гранулярное и интеллектуальное кеширование результатов RAG и OCR.
*   **Фоновые задачи:** Использование более надежной системы управления фоновыми задачами (например, Celery).