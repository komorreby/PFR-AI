# PFR-AI: Cистема аналитики для ПФР

«Разработка интеллектуальной системы автоматизированного анализа и верификации пенсионных документов с использованием методов машинного 
обучения и обработки текстов»

Прототип веб-приложения для ввода данных пенсионных дел, их анализа на предмет ошибок, **анализа соответствия законодательству с помощью RAG** и отображения истории обработанных дел.

## Основные возможности

*   **Ввод данных:** Многошаговая форма для ввода персональных данных, информации о трудовом стаже и других сведений.
*   **Анализ дела:** Отправка введенных данных на бэкенд для:
    *   Проверки на основе предобученной модели классификации ошибок.
    *   **Анализа соответствия ФЗ-400 "О страховых пенсиях" с использованием Retrieval-Augmented Generation (RAG), графа знаний для обогащения контекста и локального LLM.**
*   **Отображение истории:** Вывод списка обработанных дел с их статусом и результатами анализа.
*   **Отображение ошибок:** Вывод списка обнаруженных ошибок и рекомендаций после анализа.
*   **RAG Анализ:** Возможность запросить анализ введенных данных на соответствие законодательству и получить текстовый ответ от RAG-системы.
*   **Экспорт документов:** Загрузка результатов анализа в форматах PDF и DOCX.

## Распознавание данных с изображений документов

Система способна извлекать структурированные данные из фотографий следующих типов документов:
*   Паспорт РФ
*   СНИЛС
*   Другие пенсионные документы (справки, выписки, удостоверения и т.д.)

### Процесс распознавания:

1.  **Загрузка изображения:** Пользователь загружает изображение документа через API.
2.  **Анализ мультимодальной LLM (`qwen2.5vl`):**
    *   Для **паспортов** и **СНИЛС** модель извлекает ключевые поля согласно predefined Pydantic моделям.
    *   Для **"других" документов** модель определяет тип документа, извлекает все найденные поля, предоставляет свою оценку уверенности и полный распознанный текст.
3.  **Дополнительный анализ текстовой LLM (`qwen3`) (для "других" документов):**
    *   Результаты от `qwen2.5vl` (тип документа, извлеченные поля, оценка, полный текст) передаются модели `qwen3`.
    *   `qwen3` предоставляет развернутое осмысление документа и, что важно, **стандартизирует определенный `qwen2.5vl` тип документа** согласно предопределенному списку (`PENSION_DOCUMENT_TYPES`). Это позволяет привести разнообразные формулировки типов документов к единому стандарту.
4.  **Возврат результата:** API возвращает извлеченные и структурированные данные в формате JSON.

### Ключевые технологии и подходы:

*   **Ollama:** Используется для локального запуска мультимодальной (`qwen2.5vl:latest`) и текстовой (`qwen3:latest`) LLM.
*   **Pydantic модели:** Для валидации и структурирования извлекаемых данных (`PassportData`, `SnilsData`, `OtherDocumentData`).
*   **Промпт-инжиниринг:** Тщательно разработанные промпты для каждой модели и типа документа для повышения точности извлечения.
*   **Двухэтапный анализ для "других" документов:** Комбинация мультимодальной LLM для первичного извлечения и текстовой LLM для глубокого анализа и стандартизации.
*   **Обработка ошибок и парсинг:** Надежные механизмы для извлечения JSON из ответов LLM, включая очистку от Markdown-разметки.

## Технологический стек

### Фронтенд

*   Next.js, React
*   Daisy UI, Tailwind CSS
*   Zustand
*   TypeScript

### Бэкенд

*   FastAPI (Python 3.10+)
*   PyTorch, scikit-learn
*   LlamaIndex
*   Neo4j (граф знаний пенсионного законодательства)
*   Языковые модели:
    *   Mistral 7B (для анализа соответствия законодательству)
    *   Bert-подобная модель (для классификации ошибок в пенсионном деле)

## Архитектура системы

### Retrieval-Augmented Generation (RAG)

Система использует подход RAG для ответов на вопросы о пенсионном законодательстве:

1. **Индексация документов:** Загрузка и индексация законов о пенсионном обеспечении в векторную базу данных.
2. **Семантический поиск:** При получении запроса, система находит наиболее релевантные фрагменты текста законов.
3. **Граф знаний:** Для обогащения контекста используется Neo4j, содержащий структуру законов и связи между типами пенсий и статьями.
4. **Генерация ответа:** Локальная LLM (Mistral 7B) генерирует ответ с использованием найденного контекста.

### Граф знаний пенсионного законодательства

Система использует Neo4j для хранения структурированной информации о пенсионном законодательстве:

* **Узлы графа:**
  * Law - законы (ФЗ-400, ФЗ-166 и др.)
  * Article - статьи законов
  * PensionType - типы пенсий (страховая по старости, социальная по инвалидности и др.)

* **Связи:**
  * CONTAINS - закон содержит статью
  * RELATES_TO_PENSION_TYPE - статья относится к определённому типу пенсии

### Инструменты для диагностики и обогащения графа знаний

В проекте реализованы специальные инструменты для анализа и улучшения графа знаний:

* **`graph_validator.py`** - модуль для диагностики состояния графа и выполнения базовых исправлений:
  * Поиск изолированных статей (без связей с типами пенсий)
  * Выявление и исправление дублирующихся узлов
  * Создание базовых связей между статьями и типами пенсий

* **`graph_enricher.py`** - инструмент для обогащения графа знаний:
  * Интеграция с RAG-движком для анализа текстов статей
  * Улучшенный поиск ключевых слов для создания связей
  * Формирование подробных отчетов о состоянии графа

Использование этих инструментов позволяет существенно повысить качество и полноту графа знаний, что напрямую влияет на качество ответов системы.

#### Запуск инструментов для работы с графом

```bash
# Проверка состояния графа знаний
python -m app.graph_enricher --action status

# Применение базовых исправлений
python -m app.graph_enricher --action basic

# Исправление дублирующихся узлов
python -m app.graph_enricher --action duplicates

# Обогащение графа данными из векторного хранилища
python -m app.graph_enricher --action vector --max-nodes 500

# Полное обогащение графа (включая все вышеперечисленные действия)
python -m app.graph_enricher --action full --report graph_report.json
```

## Запуск проекта

### Требования

*   Python 3.10+
*   Node.js 20+
*   Neo4j 4.4+

### Бэкенд

```bash
cd backend
python -m pip install -r requirements.txt
uvicorn app.main:app --reload
```

### Фронтенд

```bash
cd frontend
npm install
npm run dev
```

### Инициализация Neo4j

```bash
# Запуск Neo4j в Docker
docker run \
    --publish=7474:7474 --publish=7687:7687 \
    --env=NEO4J_AUTH=neo4j/12345678 \
    neo4j:latest
```

## Структура проекта

```
PFR-AI/
├── backend/
│   ├── app/
│   │   ├── rag_core/           # Модули системы RAG
│   │   │   ├── config.py       # Конфигурация RAG и графа знаний
│   │   │   ├── engine.py       # Основной движок RAG
│   │   │   └── document_parser.py # Парсер документов с извлечением данных для графа
│   │   ├── graph_builder.py    # Построение графа знаний в Neo4j
│   │   ├── graph_validator.py  # Диагностика и валидация графа знаний
│   │   ├── graph_enricher.py   # Обогащение графа знаний
│   │   ├── crud.py             # Операции с базой данных (CRUD)
│   │   ├── database.py         # Настройка SQLAlchemy и соединения
│   │   ├── main.py             # Основной файл FastAPI (точка входа, эндпоинты)
│   │   ├── models.py           # Pydantic модели
│   │   └── services.py         # Сервисный слой (генерация документов и т.п.)
│   └── requirements.txt
├── frontend/
│   ├── app/
│   ├── components/
│   └── package.json
├── docs/
│   ├── graph_ontology.md       # Описание онтологии графа знаний
│   └── ...
└── README.md
```

## Быстрый старт

### Предпосылки

*   Установлен Python 3.9+
*   Установлен Node.js и npm/yarn
*   **Установлен и запущен Ollama** с необходимыми моделями (например, `gemma3`, `mxbai-embed-large`). Убедитесь, что Ollama доступен по адресу `http://localhost:11434`.
*   **Установлен и запущен Neo4j** для работы с графом знаний. Убедитесь, что Neo4j доступен по адресу `bolt://localhost:7687` с указанными в `backend/app/rag_core/config.py` учетными данными.

### Бэкенд

1.  Перейдите в директорию `backend`:
    ```bash
    cd backend
    ```
2.  Создайте и активируйте виртуальное окружение:
    ```bash
    python -m venv venv
    # Windows
    .\venv\Scripts\activate
    # macOS/Linux
    source ./venv/bin/activate
    ```
3.  Установите зависимости:
    ```bash
    pip install -r requirements.txt
    ```
4.  **(Первый запуск) Инициализация RAG индекса и графа знаний:** При первом запуске сервера FastAPI произойдет автоматическая индексация документа из папки `backend/data` и построение графа знаний в Neo4j. Это может занять несколько минут. Следите за логами в консоли.
5.  Запустите сервер FastAPI:
    ```bash
    uvicorn app.main:app --reload --port 8000
    ```
    Сервер будет доступен по адресу `http://127.0.0.1:8000`.

### Фронтенд

1.  Перейдите в директорию `frontend`:
    ```bash
    cd frontend
    ```
2.  Установите зависимости:
    ```bash
    npm install
    ```
3.  Запустите сервер для разработки:
    ```bash
    npm run dev
    ```
    Приложение будет доступно по адресу `http://localhost:5173` (или другому порту, указанному Vite).

## Дальнейшие шаги

*   См. `backend/README.md` для детальной информации о бэкенде.
*   См. `frontend/README.md` для детальной информации о фронтенде.