# PFR-AI: Бэкенд Анализа Пенсионных Дел

[![Python Version](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![Framework](https://img.shields.io/badge/framework-FastAPI-green.svg)](https://fastapi.tiangolo.com/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE) <!-- Замените на вашу лицензию, если она есть -->
<!-- Добавьте другие значки, если применимо (статус сборки, покрытие тестами и т.д.) -->

Серверная часть приложения для интеллектуального анализа данных пенсионных дел, построенная на FastAPI.

## Основные Возможности

*   **Прием данных:** Обработка данных пенсионного дела, переданных в формате JSON (структура определяется Pydantic-моделями).
*   **Валидация:** Проверка корректности и полноты входных данных с использованием Pydantic.
*   **Классификация Ошибок:** Запуск модели машинного обучения (scikit-learn/joblib) для выявления распространенных ошибок и несоответствий в данных дела (например, недостаточный стаж/баллы, противоречия в датах, отсутствие документов).
*   **RAG-Анализ Законодательства:** Предоставление системы Retrieval-Augmented Generation (RAG) на базе LlamaIndex для анализа описания дела на соответствие нормам пенсионного законодательства РФ (ФЗ-400, ФЗ-166).
    *   Использует локально запущенный Ollama для LLM (например, `qwen3:latest` - актуальную модель см. в `backend/app/rag_core/config.py`) и локальные модели для эмбеддингов (`jina-embeddings-v3`) и реранжирования (`cross-encoder-russian-msmarco`).
    *   Автоматически индексирует PDF-документы законов из папки `data/` при первом запуске.
    *   Применяет продвинутые техники: иерархический парсинг документов, фильтрацию по метаданным (тип пенсии, статья закона).
*   **Хранение Истории:** Сохранение информации об обработанных делах и результатах анализа в базе данных SQLite (с использованием SQLAlchemy в асинхронном режиме).
*   **Генерация Отчетов:** Возможность генерации документов (PDF/DOCX) с базовыми результатами анализа ошибок для конкретного дела.
*   **(Опционально/Отдельно) OCR Документов:** Включает скрипт `documentOCR.py` для распознавания текста из сканов/фотографий документов (паспорт, СНИЛС, трудовая) с использованием Tesseract и EasyOCR, и извлечения ключевой информации. *Примечание: На данный момент этот скрипт не интегрирован напрямую в API эндпоинты.*

## API Эндпоинты

Подробную интерактивную документацию (Swagger UI) можно найти по адресу `/docs` после запуска сервера.

*   **`GET /`**
    *   **Описание:** Проверка доступности сервера.
    *   **Ответ (200 OK):** `{"message": "PFR-AI Backend is running!"}`

*   **`POST /process`**
    *   **Описание:** Основной эндпоинт для комплексного анализа пенсионного дела. Выполняет валидацию данных, запускает классификатор ошибок, формирует объяснение с использованием RAG-анализа и сохраняет дело и результат в БД.
    *   **Тело запроса:** JSON объект, соответствующий Pydantic модели `CaseDataInput` (см. `app/models.py`).
    *   **Ответ (200 OK):** JSON объект, соответствующий Pydantic модели `ProcessOutput`, содержащий поля `status`, `explanation` и `errors`.
    *   **Ответ (422 Unprocessable Entity):** Ошибка валидации входных данных.

*   **`POST /api/v1/analyze_case`**
    *   **Описание:** Эндпоинт для выполнения RAG-анализа на основе структурированных данных о деле.
    *   **Тело запроса:** JSON объект, соответствующий Pydantic модели `CaseDataInput` (см. `app/models.py`). Внутренне данные форматируются для передачи в RAG-систему.
    *   **Ответ (200 OK):** JSON объект, соответствующий Pydantic модели `CaseAnalysisResponse`, содержащий `analysis_result` (текстовый результат анализа от RAG) и `confidence_score`.
    *   **Ответ (503 Service Unavailable):** Если RAG-движок не инициализирован.
    *   **Ответ (500 Internal Server Error):** Внутренняя ошибка при выполнении RAG-запроса.

*   **`GET /history`**
    *   **Описание:** Получение списка последних обработанных дел из базы данных.
    *   **Query Параметры:**
        *   `skip` (int, опционально, default=0): Смещение для пагинации.
        *   `limit` (int, опционально, default=100): Максимальное количество записей.
    *   **Ответ (200 OK):** Список JSON объектов, соответствующих Pydantic модели `CaseHistoryEntry`.

*   **`GET /download_document/{case_id}`**
    *   **Описание:** Скачивание сгенерированного отчета (PDF или DOCX) с базовыми ошибками для указанного дела.
    *   **Path Параметры:**
        *   `case_id` (int): ID дела из истории.
    *   **Query Параметры:**
        *   `format` (str, опционально, default='pdf'): Формат документа ('pdf' или 'docx').
    *   **Ответ (200 OK):** Файл отчета (`application/pdf` или `application/vnd.openxmlformats-officedocument.wordprocessingml.document`).
    *   **Ответ (404 Not Found):** Если дело с указанным `case_id` не найдено.
    *   **Ответ (500 Internal Server Error):** Ошибка при генерации документа.

## Установка и Запуск

1.  **Клонирование репозитория:**
    ```bash
    git clone <your-repo-url>
    cd PFR-AI/backend
    ```

2.  **Требования:**
    *   Python 3.9 или выше.
    *   **Ollama:** Установленный и запущенный Ollama (см. [https://ollama.com/](https://ollama.com/)).
    *   **Модели для Ollama:** Убедитесь, что необходимые LLM скачаны (например, `qwen3:latest` - актуальную модель см. в `backend/app/rag_core/config.py`):
        ```bash
        ollama pull qwen3:latest # Пример LLM (см. config.py)
        # ollama pull mxbai-embed-large # Пример, если бы эмбеддинги были через Ollama
        ```
        Ollama должен быть доступен по адресу `http://localhost:11434` (стандартный).
    *   **(Windows)** Tesseract OCR: Если планируется использовать `documentOCR.py`, установите Tesseract (см. [инструкции](https://tesseract-ocr.github.io/tessdoc/Installation.html)) и убедитесь, что путь к `tesseract.exe` и `tessdata` указан верно в `documentOCR.py`.
    *   **(Windows)** Poppler: Если планируется использовать `documentOCR.py` для PDF, установите Poppler (см. [инструкции](https://github.com/oschwartz10612/poppler-windows/releases/)) и укажите путь к папке `bin` в `documentOCR.py`.

3.  **Виртуальное окружение:**
    ```bash
    python -m venv venv
    # Windows
    .\venv\Scripts\activate
    # macOS/Linux
    source ./venv/bin/activate
    ```

4.  **Установка зависимостей:**
    *Примечание: Установка зависимостей, особенно `torch` и связанных с ним библиотек для эмбеддингов/реранкера, может занять время и потребовать значительного дискового пространства.*
    ```bash
    pip install -r requirements.txt
    ```

5.  **(Опционально) Конфигурация:**
    *   Основные параметры RAG (имена моделей, пути) настраиваются в `backend/app/rag_core/config.py`.
    *   Рекомендуется использовать переменные окружения для переопределения настроек (например, `OLLAMA_BASE_URL`). Можно создать файл `.env` в папке `backend/` (поддерживается `python-dotenv`):
      ```dotenv
      # Пример .env файла
      # OLLAMA_BASE_URL=http://другой_хост:11434
      # LOGGING_LEVEL=DEBUG
      ```

6.  **Индексация RAG (при первом запуске):**
    *   При первом запуске сервера будет выполнена индексация PDF-документов из папки `backend/data/`. Это **необходимо** для работы RAG-системы и может занять **значительное время** (от нескольких минут до десятков минут в зависимости от объема документов и мощности системы).
    *   Следите за логами сервера для отслеживания прогресса. Файлы индекса будут сохранены в `backend/data/`.

7.  **Запуск сервера:**
    ```bash
    uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
    ```
    *   Сервер будет доступен по адресу `http://127.0.0.1:8000`.
    *   Интерактивная документация API (Swagger UI): `http://127.0.0.1:8000/docs`.
    *   Опция `--reload` автоматически перезапускает сервер при изменениях в коде (удобно для разработки).

## Структура Кода (Текущая)
