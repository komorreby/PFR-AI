План по Созданию и Интеграции Графа Знаний (KG)
Фаза I: Проектирование и Подготовка
Цель: Заложить прочный фундамент для графа знаний, определив его структуру и выбрав инструменты.

Этап 1: Определение Онтологии Графа (Schema Definition)

Задача: Создать формальное описание типов информации (сущностей) и их взаимосвязей (отношений), которые будут храниться в графе. Это "скелет" вашего графа знаний.

Ключевые действия:

Шаг 1.1: Анализ Предметной Области и Определение Ключевых Сущностей (Nodes).

Что делать:

Провести глубокий анализ текстов пенсионного законодательства (ФЗ-400, ФЗ-166 и др.), уделяя особое внимание часто встречающимся понятиям, их определениям и роли в процессе назначения пенсии.

Определить пилотный набор пользовательских запросов (например, "условия назначения страховой пенсии по старости", "досрочная пенсия для северян", "какие документы нужны для социальной пенсии по инвалидности").

На основе анализа и запросов составить первоначальный список типов сущностей.

Примеры: Закон, СтатьяЗакона, ПунктСтатьи, УсловиеНазначенияПенсии, ТипПенсии, КатегорияГраждан, Документ, Льгота, КлючевойТермин (например, "страховой стаж", "ИПК", "пенсионный возраст").

Обсуждение/Решение: Какие 3-5 типов сущностей являются абсолютно критичными для пилотного запуска?

Шаг 1.2: Определение Атрибутов для Каждого Типа Сущностей.

Что делать: Для каждого выбранного типа сущности определить набор свойств, которые его характеризуют.

Пример для СтатьяЗакона:

id_статьи (уникальный идентификатор, например, "ФЗ-400_Ст.8")

номер_статьи (текстовый, например, "Статья 8", "8.1")

название_статьи (если есть, например, "Условия назначения страховой пенсии по старости")

текст_статьи_оригинал (полный текст статьи или наиболее репрезентативный фрагмент)

ссылка_на_чанк_в_векторной_БД (если текст статьи разбит на чанки для векторного поиска)

принадлежит_закону (ссылка на сущность Закон)

версия_редакции (если актуально)

Пример для УсловиеНазначенияПенсии:

id_условия (уникальный идентификатор)

описание_условия (например, "Достижение возраста X лет")

значение_условия (например, "65 лет", "15 лет", "30 баллов")

нормативная_ссылка (ссылка на СтатьяЗакона или ПунктСтатьи, где это условие определено)

Обсуждение/Решение: Какие атрибуты обязательны, а какие опциональны для каждого типа сущности на пилотном этапе? Как обеспечить уникальность идентификаторов?

Шаг 1.3: Определение Основных Типов Отношений (Edges).

Что делать: Описать, как определенные типы сущностей могут быть связаны друг с другом. Отношения должны отражать семантические связи в предметной области.

Примеры:

(Закон) -[СОДЕРЖИТ]-> (СтатьяЗакона)

(СтатьяЗакона) -[СОДЕРЖИТ]-> (ПунктСтатьи)

(СтатьяЗакона) -[РЕГУЛИРУЕТ]-> (ТипПенсии)

(СтатьяЗакона) -[УСТАНАВЛИВАЕТ_УСЛОВИЕ]-> (УсловиеНазначенияПенсии)

(ТипПенсии) -[ТРЕБУЕТ_ДОКУМЕНТ]-> (Документ)

(УсловиеНазначенияПенсии) -[ПРИМЕНИМО_К_КАТЕГОРИИ]-> (КатегорияГраждан)

(СтатьяЗакона_А) -[ССЫЛАЕТСЯ_НА]-> (СтатьяЗакона_Б)

Обсуждение/Решение: Какие 2-3 типа отношений наиболее важны для улучшения поиска и понимания контекста LLM на первом этапе?

Шаг 1.4: (Опционально) Определение Атрибутов для Отношений.

Что делать: В некоторых случаях сами отношения могут иметь атрибуты.

Пример: Отношение (СтатьяЗакона) -[ССЫЛАЕТСЯ_НА {тип_ссылки: "уточнение", дата_ссылки: "..."}]-> (СтатьяЗакона)

Обсуждение/Решение: Нужны ли атрибуты для отношений на пилотном этапе?

Шаг 1.5: Визуализация и Документирование Онтологии.

Что делать:

Создать диаграмму онтологии (например, с помощью draw.io, Lucidchart или специализированных инструментов для моделирования онтологий).

Подготовить документ, описывающий все типы сущностей, их атрибуты (с типами данных и примерами), все типы отношений и их возможные пары (субъект-объект).

Результат: Четко определенная и задокументированная схема графа.

Этап 2: Выбор Технологического Стека и Подготовка Инфраструктуры

Задача: Выбрать инструменты для создания, хранения и взаимодействия с графом знаний.

Ключевые действия:

Шаг 2.1: Выбор Графовой СУБД.

Что делать:

Проанализировать доступные графовые СУБД (Neo4j, Amazon Neptune, ArangoDB, RDF-хранилища типа Apache Jena/Stardog, TigerGraph).

Оценить их по критериям: простота установки и использования, язык запросов (Cypher, Gremlin, SPARQL), производительность, масштабируемость, поддержка сообщества, наличие Python-драйверов, интеграция с LlamaIndex.

Рекомендация для старта: Neo4j часто является хорошим выбором из-за зрелости, удобного языка Cypher и хорошей поддержки.

Обсуждение/Решение: Какая СУБД будет использоваться для пилотного проекта? Будет ли она развернута локально или в облаке?

Шаг 2.2: Установка и Настройка Графовой СУБД.

Что делать: Установить выбранную СУБД (например, Neo4j Desktop для локальной разработки). Освоить базовые команды администрирования и взаимодействия с СУБД.

Результат: Рабочее окружение графовой СУБД.

Шаг 2.3: Выбор Инструментов для Извлечения Сущностей и Отношений (NER & RE).

Что делать:

Для Rule-based NER/RE: Подготовить набор регулярных выражений (на основе существующих в document_parser.py и новых) и словарей ключевых терминов (для условий, типов пенсий и т.д.).

Для ML-based NER/RE (если планируется):

Исследовать готовые русскоязычные модели: Natasha, spaCy (с русской моделью ru_core_news_sm/md/lg), DeepPavlov.

Оценить их качество "из коробки" на примерах ваших текстов.

Рассмотреть возможность использования Hugging Face Transformers для доступа к более широкому спектру моделей.

Для LLM-based NER/RE: Подготовить шаблоны промптов для вашей LLM (Qwen2), ориентированные на извлечение сущностей и триплетов (субъект, предикат, объект) из текстовых фрагментов.

Обсуждение/Решение: Какой подход или комбинация подходов к NER/RE будет использоваться на первом этапе? Какие библиотеки Python будут задействованы (re, Natasha, spaCy, transformers)?

Шаг 2.4: Подготовка Окружения для Разработки Скриптов Извлечения.

Что делать: Настроить Python-окружение с необходимыми библиотеками (драйвер для графовой СУБД, библиотеки для NER/RE).

Результат: Готовность к написанию кода для наполнения графа.

Фаза II: Реализация Извлечения и Построения Графа
Цель: Наполнить граф знаниями, извлеченными из документов.

Этап 3: Извлечение Данных (Information Extraction)

Задача: Автоматически извлечь сущности и отношения из текстовых документов в соответствии с разработанной онтологией.

Ключевые действия:

Шаг 3.1: Адаптация Существующего Парсера Документов.

Что делать:

Модифицировать document_parser.py (или создать новый модуль), чтобы он не только разбивал текст на чанки и извлекал базовую метаинформацию (имя файла, статья из заголовка), но и подготавливал текст для более глубокого NER/RE.

Возможно, потребуется более гранулярное разбиение или сохранение исходной структуры документа для лучшего контекста при извлечении отношений.

Результат: Функция или класс, возвращающий текст и его структурные метаданные, готовые для NER/RE.

Шаг 3.2: Реализация Модуля NER.

Что делать (выбрать один или комбинацию подходов):

Rule-based NER: Написать Python-функции, использующие регулярные выражения и словари для поиска и классификации сущностей (например, "Статья X", "ФЗ-Y", "пенсионный возраст", "страховая пенсия по старости").

ML-based NER: Интегрировать выбранную ML-библиотеку (Natasha, spaCy) для распознавания сущностей. Возможно, потребуется создать кастомные компоненты или дообучить модель на небольшом аннотированном наборе данных, если качество стандартных моделей будет недостаточным.

LLM-based NER: Написать функцию, которая отправляет чанки текста LLM с промптом для извлечения сущностей и их типов. Обработать ответ LLM.

Результат: Модуль, который на вход получает текст (чанк), а на выходе возвращает список найденных сущностей с их типами, текстовыми значениями и позициями в тексте.

Шаг 3.3: Реализация Модуля RE.

Что делать (выбрать один или комбинацию подходов):

Rule-based RE: Разработать правила (на основе ключевых слов, синтаксических шаблонов, близости сущностей в тексте) для определения отношений между сущностями, найденными модулем NER.

Пример: Если в одном предложении найдены СтатьяЗакона и УсловиеНазначенияПенсии, и между ними есть глагол "устанавливает", то создать отношение УСТАНАВЛИВАЕТ_УСЛОВИЕ.

LLM-based RE: Написать функцию, которая отправляет LLM текст (или пары сущностей с контекстом) с промптом для определения типа отношения между ними или извлечения полных триплетов.

Результат: Модуль, который на вход получает список сущностей (из NER) и текст, а на выходе возвращает список триплетов отношений (сущность1_id, тип_отношения, сущность2_id).

Шаг 3.4: Реализация Процесса Нормализации Сущностей.

Что делать:

Создать механизм для приведения извлеченных сущностей к каноническому виду. Например, "статья 8", "ст. 8", "восьмая статья" ФЗ-400 должны отображаться на один уникальный узел в графе, представляющий "Статья 8 ФЗ-400".

Это может включать словари синонимов, правила нормализации строк, возможно, использование ID из внешних справочников.

Результат: Функция, которая преобразует "сырые" извлеченные сущности в их нормализованные идентификаторы, используемые в графе.

Шаг 3.5: Сборка Пайплайна Извлечения.

Что делать: Написать основной скрипт, который:

Загружает документы с помощью loader.py.

Парсит их с помощью document_parser.py (возможно, адаптированного).

Для каждого чанка/документа:

Применяет NER.

Применяет RE.

Нормализует сущности.

Сохраняет извлеченные сущности (с атрибутами) и отношения (триплеты) в промежуточном формате (например, списки словарей, JSON-файлы) для последующей загрузки в граф.

Результат: Набор файлов с данными для графа.

Шаг 3.6: Оценка Качества Извлечения (пилотная).

Что делать:

Вручную разметить небольшой пилотный набор текстов (несколько статей закона) на предмет сущностей и отношений.

Запустить пайплайн извлечения на этих текстах.

Сравнить результаты автоматического извлечения с ручной разметкой. Оценить точность (precision) и полноту (recall).

Итеративно улучшать правила/промпты/модели на основе анализа ошибок.

Результат: Понимание качества извлечения и направления для улучшения.

Этап 4: Построение и Хранение Графа

Задача: Загрузить извлеченные данные в графовую СУБД и убедиться в корректности структуры графа.

Ключевые действия:

Шаг 4.1: Разработка Скриптов для Загрузки Данных в Граф.

Что делать:

Написать Python-скрипты, использующие драйвер выбранной графовой СУБД (например, neo4j-driver для Neo4j).

Скрипты должны:

Читать промежуточные файлы с извлеченными сущностями и отношениями.

Для каждой сущности: создавать узел в графе с соответствующим типом (меткой) и атрибутами. Обеспечить уникальность узлов (например, через MERGE в Cypher на основе ID сущности).

Для каждого отношения: создавать ребро в графе между соответствующими узлами с указанием типа отношения.

Результат: Скрипты для наполнения/обновления графа.

Шаг 4.2: Первичная Загрузка Данных в Граф.

Что делать: Запустить скрипты загрузки на данных, извлеченных из пилотного набора документов.

Результат: Граф знаний, содержащий информацию из пилотных документов.

Шаг 4.3: Тестирование Запросов к Графу и Валидация Структуры.

Что делать:

Написать и выполнить несколько тестовых запросов на языке графовой СУБД (например, Cypher).

Примеры запросов: "Найти все статьи Закона ФЗ-400", "Найти все условия назначения страховой пенсии по старости и статьи, которые их устанавливают", "Найти все документы, требуемые для пенсии по инвалидности".

Проверить, что граф построен корректно, узлы и ребра созданы в соответствии с онтологией, атрибуты заполнены.

Использовать инструменты визуализации графа (например, Neo4j Browser) для инспекции.

Результат: Уверенность в корректности построенного графа.

Шаг 4.4: Планирование Обновления Графа.

Что делать: Продумать, как граф будет обновляться при изменениях в законодательстве или улучшении моделей извлечения. Будет ли это полная перезаливка или инкрементальное обновление?

Результат: Стратегия поддержки графа в актуальном состоянии.

Фаза III: Интеграция Графа с RAG-Системой и Тестирование
Цель: Использовать граф знаний для улучшения процесса поиска и генерации ответов в существующей RAG-системе.

Этап 5: Интеграция Графа с RAG-Пайплайном (engine.py)

Задача: Модифицировать RAG-систему для использования графа знаний на этапе ретривинга и/или обогащения контекста.

Ключевые действия:

Шаг 5.1: Проектирование Способа Интеграции Графа.

Что делать: Выбрать один из способов интеграции (или их комбинацию):

А) Graph Retriever: Извлечение сущностей из запроса пользователя, формирование графового запроса, получение релевантных узлов/текстов из графа.

Б) Гибридный поиск: Параллельный векторный поиск и поиск по графу, с последующим объединением и переранжированием результатов.

В) Расширение контекста: Начальный векторный поиск, затем использование графа для нахождения связанных узлов и добавления их текстов в контекст.

Рекомендация для старта: Начать с варианта (А) или (В) как более простых для первой итерации.

Обсуждение/Решение: Какой способ интеграции будет реализован в первую очередь?

Шаг 5.2: Реализация Логики Извлечения Сущностей из Запроса Пользователя.

Что делать:

В методе query или _retrieve_nodes файла engine.py добавить логику для анализа текста запроса пользователя (case_description или query_bundle.query_str).

Использовать тот же NER-модуль (rule-based, ML или LLM-based), что и для наполнения графа, или упрощенную его версию, для идентификации ключевых сущностей (например, тип пенсии, категория граждан, условие).

Результат: Функция, возвращающая список сущностей, найденных в запросе.

Шаг 5.3: Реализация Формирования и Выполнения Графовых Запросов.

Что делать:

На основе сущностей, извлеченных из запроса пользователя, и выбранного способа интеграции, написать логику для динамического формирования запросов к графовой СУБД (например, строк Cypher).

Интегрировать Python-драйвер графовой СУБД для выполнения этих запросов.

Обработать результаты: извлечь ID статей, тексты, метаданные из узлов, полученных от графа.

Пример: Если из запроса извлечены "досрочная пенсия" (ТипПенсии) и "северяне" (КатегорияГраждан), сформировать Cypher-запрос, который ищет статьи, связанные с этими двумя сущностями.

Результат: Функция _retrieve_from_graph(query_bundle: QueryBundle) -> List[NodeWithScore] (или аналогичная), возвращающая узлы, найденные через граф.

Шаг 5.4: Модификация Метода _retrieve_nodes.

Что делать:

Интегрировать вызов новой функции _retrieve_from_graph в существующий метод _retrieve_nodes.

Реализовать логику объединения результатов векторного поиска и графового поиска (если используется гибридный подход). Это может включать дедупликацию узлов, присвоение весов результатам из разных источников.

Результат: Обновленный _retrieve_nodes, использующий граф.

Шаг 5.5: Адаптация Этапа Re-ranking.

Что делать: Убедиться, что узлы, полученные из графа (и их скоры, если есть), корректно обрабатываются существующим реранкером _rerank_nodes. Возможно, потребуется адаптировать логику скоринга или передачу метаданных.

Результат: Реранкер, работающий с объединенным набором кандидатов.

Шаг 5.6: Адаптация Этапа Построения Промпта (_build_prompt).

Что делать:

Модифицировать _build_prompt так, чтобы он мог использовать дополнительную структурированную информацию, полученную из графа.

Например, если граф показывает явную связь между двумя статьями, эту информацию можно включить в промпт, чтобы LLM лучше поняла контекст.

Метаданные из узлов графа (названия статей, типы условий) также могут быть использованы для более информативного контекста.

Результат: Улучшенный промпт, обогащенный знаниями из графа.

Этап 6: Тестирование и Оценка

Задача: Оценить влияние графа знаний на качество работы RAG-системы.

Ключевые действия:

Шаг 6.1: Разработка Сценариев Тестирования.

Что делать: Подготовить набор тестовых запросов, включая те, на которых текущая система испытывает трудности или где граф потенциально может дать значительное улучшение (например, запросы, требующие понимания связей между несколькими законами/статьями, или запросы с неявными условиями).

Результат: Набор тестовых кейсов.

Шаг 6.2: Проведение Сквозного Тестирования.

Что делать: Запустить тестовые запросы через обновленный RAG-пайплайн. Собрать ответы LLM.

Результат: Результаты работы системы с интегрированным графом.

Шаг 6.3: Сравнительный Анализ Результатов.

Что делать:

Сравнить ответы системы с графом и без графа (если возможно сохранить предыдущую версию или проводить A/B тестирование).

Оценить по критериям: релевантность найденных источников, точность и полнота ответа LLM, корректность ссылок на законодательство.

Можно использовать как качественные оценки (экспертный анализ ответов), так и количественные (если есть метрики, например, точность отнесения к категории "соответствует" / "не соответствует").

Результат: Выводы о влиянии графа знаний на производительность системы.

Фаза IV: Итерации и Развитие
Цель: Постоянное улучшение графа знаний и его интеграции.

Этап 7: Итеративное Улучшение

Задача: На основе результатов тестирования и обратной связи дорабатывать граф и RAG-систему.

Ключевые действия:

Шаг 7.1: Анализ Ошибок и Недостатков.

Что делать: Выявить случаи, где граф не помог или привел к ухудшению результатов. Проанализировать причины (неполная онтология, ошибки извлечения, неэффективные графовые запросы, проблемы интеграции).

Шаг 7.2: Расширение Онтологии.

Что делать: Добавлять новые типы сущностей и отношений по мере необходимости.

Шаг 7.3: Улучшение Моделей/Правил Извлечения.

Что делать: Дорабатывать NER/RE компоненты для повышения точности и полноты.

Шаг 7.4: Оптимизация Запросов к Графу.

Что делать: Пересматривать и оптимизировать графовые запросы для повышения производительности.

Шаг 7.5: Рассмотрение Более Продвинутых Техник.

Что делать: Исследовать возможность использования логического вывода на графе (inference), обучения графовых эмбеддингов для улучшения поиска, более сложных алгоритмов обхода графа.

